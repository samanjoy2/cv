---
title: 'BanglaClickBERT: Bangla Clickbait Detection from News Headlines using Domain Adaptive BanglaBERT and MLP Techniques'

# Authors
authors:
  - Saman Sarker Joy
  - Tanusree Das Aishi
  - Naima Tahsin Nodi
  - Annajiat Alim Rasel

# Author notes (optional)
author_notes:
  # - 'Equal contribution'
  # - 'Equal contribution'

date: '2023-11-01T00:00:00Z'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2023-11-01T00:00:00Z'

# Publication type.
publication_types: ['2']

# Publication name and optional abbreviated publication name.
publication: In *Proceedings of the 21st Annual Workshop of the Australasian Language Technology Association*
publication_short: In *ALTA 2023*

abstract: News headlines or titles that deliberately persuade readers to view a particular online content are referred to as clickbait. While numerous studies have focused on clickbait detection in English, there has been limited research addressing clickbait detection in Bangla news headlines. In this study, we experimented with several transformers models, including BanglaBERT and XLM-RoBERTa, and introduced a domain-adaptive pretrained model, BanglaClickBERT. The dataset included 15,056 labeled and 65,406 unlabeled news headlines, further supplemented by an additional 1 million unlabeled headlines scraped from clickbait-dense websites. Our approach surpassed existing state-of-the-art technologies, providing a more accurate and efficient solution for detecting clickbait in Bangla news headlines.

# Summary. An optional shortened abstract.
summary: This paper presents BanglaClickBERT, a domain-adaptive BanglaBERT model, for detecting clickbait in Bangla news headlines. The model outperforms existing methods by leveraging a large dataset of labeled and unlabeled Bangla news headlines.

tags:
  - Clickbait Detection
  - Bangla NLP
  - Transformers
  - Domain Adaptation
  - BanglaBERT

# Display this page in the Featured widget?
featured: true

# Custom links (uncomment lines below)
links:
- name: View Paper
  url: https://aclanthology.org/2023.alta-1.1.pdf

# url_pdf: 'aclanthology.org/2023.alta-1.1.pdf'
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'BanglaClickBERT Model Overview'
  focal_point: 'Center'
  preview_only: false

# Associated Projects (optional).
projects:
  - banglaclickbert

# Slides (optional).
slides: ""
---

{{% callout note %}}
Click the _Cite_ button above to download the _.bib_ file.
{{% /callout %}}

<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
